# Example environment variables for embedding configuration
# Copy to .env.local and configure according to your chosen vendor

# =============================================================================
# EMBEDDING VENDOR CONFIGURATION
# =============================================================================

# Choose your embedding vendor: openai, azure-openai, google, or mock
EMBEDDING_VENDOR=mock

# Model configuration (vendor-specific)
EMBEDDING_MODEL=text-embedding-3-small
EMBEDDING_DIMENSIONS=1536

# API Configuration
EMBEDDING_API_KEY=your-api-key-here
EMBEDDING_BATCH_SIZE=100
EMBEDDING_RATE_LIMIT_DELAY=100

# =============================================================================
# OPENAI CONFIGURATION
# =============================================================================
# Uncomment and configure for OpenAI embeddings

# EMBEDDING_VENDOR=openai
# EMBEDDING_MODEL=text-embedding-3-small  # or text-embedding-3-large
# EMBEDDING_API_KEY=sk-your-openai-api-key
# EMBEDDING_DIMENSIONS=1536  # 1536 for small, 3072 for large

# =============================================================================
# AZURE OPENAI CONFIGURATION  
# =============================================================================
# Uncomment and configure for Azure OpenAI embeddings

# EMBEDDING_VENDOR=azure-openai
# EMBEDDING_MODEL=text-embedding-ada-002  # your deployment name
# EMBEDDING_API_KEY=your-azure-api-key
# AZURE_OPENAI_ENDPOINT=https://your-resource.openai.azure.com
# AZURE_OPENAI_API_VERSION=2024-02-01
# EMBEDDING_DIMENSIONS=1536

# =============================================================================
# GOOGLE VERTEX AI CONFIGURATION
# =============================================================================
# Uncomment and configure for Google Vertex AI embeddings

# EMBEDDING_VENDOR=google
# EMBEDDING_MODEL=textembedding-gecko@latest
# EMBEDDING_API_KEY=your-google-access-token
# GOOGLE_PROJECT_ID=your-project-id
# GOOGLE_REGION=us-central1
# EMBEDDING_DIMENSIONS=768

# =============================================================================
# DEVELOPMENT/TESTING CONFIGURATION
# =============================================================================
# Use mock embeddings for development (no API key required)

# EMBEDDING_VENDOR=mock
# EMBEDDING_DIMENSIONS=1536

# =============================================================================
# ADVANCED CONFIGURATION
# =============================================================================

# Batch processing settings
# EMBEDDING_BATCH_SIZE=50        # Reduce if hitting rate limits
# EMBEDDING_RATE_LIMIT_DELAY=200 # Increase if getting 429 errors

# Template repository settings (if using node template repository)
USE_TEMPLATE_REPOSITORY=true
AUTO_INGEST_TEMPLATES=true

# =============================================================================
# NOTES
# =============================================================================
# 
# 1. For production, use real AI vendor embeddings (OpenAI, Azure, Google)
# 2. For development, mock embeddings work fine and don't require API keys
# 3. Always use environment variables for API keys - never hardcode them
# 4. Check the EMBEDDING_CONFIG.md file for detailed configuration instructions
# 5. Test your configuration with: npm run embedding:test (if implemented)
#
# API Key Security:
# - Never commit API keys to version control
# - Use separate API keys for development and production
# - Rotate API keys regularly
# - Monitor API usage and costs
#
# Model Selection:
# - OpenAI text-embedding-3-small: Good balance of cost and performance
# - OpenAI text-embedding-3-large: Best performance, higher cost
# - Azure OpenAI: Enterprise-grade with data residency controls
# - Google Vertex AI: Good for multilingual use cases
# Prometheus configuration for Zeal monitoring

prometheus:
  prometheusSpec:
    # Retention period
    retention: 30d
    retentionSize: 50GB
    
    # Storage configuration
    storageSpec:
      volumeClaimTemplate:
        spec:
          storageClassName: local-path
          resources:
            requests:
              storage: 50Gi
    
    # Resource limits
    resources:
      requests:
        cpu: 500m
        memory: 2Gi
      limits:
        cpu: 2000m
        memory: 4Gi
    
    # Additional scrape configs for Zeal components
    additionalScrapeConfigs:
      - job_name: 'zeal-app'
        kubernetes_sd_configs:
          - role: pod
            namespaces:
              names:
                - zeal-production
        relabel_configs:
          - source_labels: [__meta_kubernetes_pod_label_app]
            action: keep
            regex: zeal
          - source_labels: [__meta_kubernetes_pod_name]
            target_label: pod
          - source_labels: [__meta_kubernetes_namespace]
            target_label: namespace
      
      - job_name: 'crdt-server'
        kubernetes_sd_configs:
          - role: pod
            namespaces:
              names:
                - zeal-production
        relabel_configs:
          - source_labels: [__meta_kubernetes_pod_label_app]
            action: keep
            regex: crdt-server
      
      - job_name: 'postgres-exporter'
        static_configs:
          - targets: ['postgres-metrics:9187']
      
      - job_name: 'redis-exporter'
        static_configs:
          - targets: ['redis-metrics:9121']
    
    # Alert rules
    additionalPrometheusRulesMap:
      zeal-alerts:
        groups:
          - name: zeal.rules
            interval: 30s
            rules:
              # Application alerts
              - alert: ZealHighErrorRate
                expr: |
                  rate(zeal_http_requests_total{status=~"5.."}[5m]) > 0.05
                for: 5m
                labels:
                  severity: warning
                annotations:
                  summary: "High error rate detected"
                  description: "{{ $labels.instance }} has error rate above 5%"
              
              - alert: ZealHighLatency
                expr: |
                  histogram_quantile(0.95, rate(zeal_http_duration_seconds_bucket[5m])) > 1
                for: 5m
                labels:
                  severity: warning
                annotations:
                  summary: "High request latency"
                  description: "95th percentile latency is above 1 second"
              
              # Database alerts
              - alert: PostgreSQLDown
                expr: up{job="postgres-exporter"} == 0
                for: 1m
                labels:
                  severity: critical
                annotations:
                  summary: "PostgreSQL is down"
                  description: "PostgreSQL database is not responding"
              
              - alert: PostgreSQLHighConnections
                expr: |
                  pg_stat_database_numbackends / pg_settings_max_connections > 0.8
                for: 5m
                labels:
                  severity: warning
                annotations:
                  summary: "PostgreSQL connection pool near limit"
                  description: "Using {{ $value | humanizePercentage }} of max connections"
              
              # Redis alerts
              - alert: RedisDown
                expr: up{job="redis-exporter"} == 0
                for: 1m
                labels:
                  severity: critical
                annotations:
                  summary: "Redis is down"
                  description: "Redis server is not responding"
              
              - alert: RedisHighMemory
                expr: |
                  redis_memory_used_bytes / redis_memory_max_bytes > 0.9
                for: 5m
                labels:
                  severity: warning
                annotations:
                  summary: "Redis memory usage high"
                  description: "Redis using {{ $value | humanizePercentage }} of max memory"
              
              # CRDT Server alerts
              - alert: CRDTServerDown
                expr: up{job="crdt-server"} == 0
                for: 1m
                labels:
                  severity: critical
                annotations:
                  summary: "CRDT server is down"
                  description: "CRDT synchronization server is not responding"
              
              - alert: CRDTSyncLag
                expr: |
                  crdt_sync_lag_seconds > 5
                for: 5m
                labels:
                  severity: warning
                annotations:
                  summary: "CRDT sync lag detected"
                  description: "CRDT sync is lagging by {{ $value }} seconds"
              
              # Resource alerts
              - alert: PodCPUUsageHigh
                expr: |
                  rate(container_cpu_usage_seconds_total{namespace="zeal-production"}[5m]) > 0.8
                for: 5m
                labels:
                  severity: warning
                annotations:
                  summary: "High CPU usage"
                  description: "Pod {{ $labels.pod }} CPU usage above 80%"
              
              - alert: PodMemoryUsageHigh
                expr: |
                  container_memory_usage_bytes{namespace="zeal-production"} / container_spec_memory_limit_bytes > 0.9
                for: 5m
                labels:
                  severity: warning
                annotations:
                  summary: "High memory usage"
                  description: "Pod {{ $labels.pod }} memory usage above 90%"
              
              # Volume alerts
              - alert: PersistentVolumeSpaceLow
                expr: |
                  kubelet_volume_stats_available_bytes / kubelet_volume_stats_capacity_bytes < 0.1
                for: 5m
                labels:
                  severity: warning
                annotations:
                  summary: "Low disk space on PV"
                  description: "PV {{ $labels.persistentvolumeclaim }} has less than 10% free space"

# Grafana configuration
grafana:
  adminPassword: changeme
  
  ingress:
    enabled: true
    hosts:
      - grafana.zeal.local
    tls:
      - secretName: grafana-tls
        hosts:
          - grafana.zeal.local
  
  persistence:
    enabled: true
    size: 10Gi
  
  datasources:
    datasources.yaml:
      apiVersion: 1
      datasources:
        - name: Prometheus
          type: prometheus
          url: http://prometheus-kube-prometheus-prometheus:9090
          isDefault: true
        - name: Loki
          type: loki
          url: http://loki:3100
  
  dashboardProviders:
    dashboardproviders.yaml:
      apiVersion: 1
      providers:
        - name: 'zeal-dashboards'
          orgId: 1
          folder: 'Zeal'
          type: file
          disableDeletion: true
          updateIntervalSeconds: 10
          allowUiUpdates: false
          options:
            path: /var/lib/grafana/dashboards/zeal
  
  dashboardsConfigMaps:
    zeal: grafana-dashboards

# AlertManager configuration
alertmanager:
  alertmanagerSpec:
    storage:
      volumeClaimTemplate:
        spec:
          storageClassName: local-path
          resources:
            requests:
              storage: 10Gi
    
    config:
      global:
        resolve_timeout: 5m
      
      route:
        group_by: ['alertname', 'cluster', 'service']
        group_wait: 10s
        group_interval: 10s
        repeat_interval: 12h
        receiver: 'default'
        routes:
          - match:
              severity: critical
            receiver: critical-receiver
            continue: true
      
      receivers:
        - name: 'default'
          # Configure your notification channels
          
        - name: 'critical-receiver'
          # Configure critical alerts channel
      
      inhibit_rules:
        - source_match:
            severity: 'critical'
          target_match:
            severity: 'warning'
          equal: ['alertname', 'cluster', 'service']